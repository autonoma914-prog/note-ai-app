# -*- coding: utf-8 -*-
# Autonoma: Experiment Notes + Kaneko-style Regression & AD Analysis (Integrated Full Version)

import os
from datetime import date

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st

from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR, OneClassSVM
from sklearn.model_selection import KFold, cross_val_predict, GridSearchCV
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import WhiteKernel, RBF, ConstantKernel, Matern, DotProduct
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.neighbors import NearestNeighbors

# ------------------------------------------------------------
# è¨­å®š
# ------------------------------------------------------------
NOTE_FILE = "notes.csv"
CSV_FILE = "experiment_data.csv"

# Streamlit ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="Autonoma", layout="centered")
st.title("Autonoma")

# SessionState: å‹•çš„ãªæ¡ä»¶æ•°
if "num_conditions" not in st.session_state:
    st.session_state.num_conditions = 1  # æœ€åˆã¯æ¡ä»¶1ã ã‘

# åˆæœŸãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
if not os.path.exists(NOTE_FILE):
    df = pd.DataFrame(columns=["å®Ÿé¨“ID", "æ—¥ä»˜", "ç›®çš„", "çµæœ", "è€ƒå¯Ÿ"])
    df.to_csv(NOTE_FILE, index=False, encoding="utf-8")

if not os.path.exists(CSV_FILE):
    df = pd.DataFrame(columns=["å®Ÿé¨“ID", "æ¡ä»¶1", "çµæœ"])
    df.to_csv(CSV_FILE, index=False, encoding="utf-8")

# ------------------------------------------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ------------------------------------------------------------
def autoscale_fit_transform(X, y):
    """X, y ã‚’ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€‚å¹³å‡ãƒ»æ¨™æº–åå·®ã¨å…±ã«è¿”ã™"""
    X = np.asarray(X, dtype=float)
    y = np.asarray(y, dtype=float)

    X_mean = X.mean(axis=0)
    X_std = X.std(axis=0, ddof=0)
    y_mean = y.mean()
    y_std = y.std(ddof=0)

    # ã‚¼ãƒ­å‰²å›é¿ï¼ˆstd=0ã¯1ã«ï¼‰
    X_std_safe = np.where(X_std == 0, 1.0, X_std)
    y_std_safe = 1.0 if y_std == 0 else y_std

    X_auto = (X - X_mean) / X_std_safe
    y_auto = (y - y_mean) / y_std_safe
    return X_auto, y_auto, (X_mean, X_std_safe, y_mean, y_std_safe)

def autoscale_transform(X_new, scalers):
    X_mean, X_std, _, _ = scalers
    X_new = np.asarray(X_new, dtype=float)
    return (X_new - X_mean) / X_std

def inverse_scale_y(y_scaled, scalers):
    _, _, y_mean, y_std = scalers
    return y_scaled * y_std + y_mean

def build_kernels(n_features):
    """Kanekoå¼ã®11ã‚«ãƒ¼ãƒãƒ«å®šç¾©"""
    return [
        ConstantKernel() * DotProduct() + WhiteKernel(),
        ConstantKernel() * RBF() + WhiteKernel(),
        ConstantKernel() * RBF() + WhiteKernel() + ConstantKernel() * DotProduct(),
        ConstantKernel() * RBF(np.ones(n_features)) + WhiteKernel(),
        ConstantKernel() * RBF(np.ones(n_features)) + WhiteKernel() + ConstantKernel() * DotProduct(),
        ConstantKernel() * Matern(nu=1.5) + WhiteKernel(),
        ConstantKernel() * Matern(nu=1.5) + WhiteKernel() + ConstantKernel() * DotProduct(),
        ConstantKernel() * Matern(nu=0.5) + WhiteKernel(),
        ConstantKernel() * Matern(nu=0.5) + WhiteKernel() + ConstantKernel() * DotProduct(),
        ConstantKernel() * Matern(nu=2.5) + WhiteKernel(),
        ConstantKernel() * Matern(nu=2.5) + WhiteKernel() + ConstantKernel() * DotProduct(),
    ]

def gamma_by_gram_variance(X_auto, gamma_grid):
    """åˆ†æ•£æœ€å¤§åŒ–ã§ RBF gamma ã‚’é¸æŠ"""
    XA = np.asarray(X_auto, dtype=float)
    var_list = []
    for g in gamma_grid:
        # RBF Gram matrix
        d2 = ((XA[:, None, :] - XA[None, :, :]) ** 2).sum(axis=2)
        K = np.exp(-g * d2)
        var_list.append(K.var(ddof=1))
    idx = int(np.argmax(var_list))
    return gamma_grid[idx]

def make_candidates_uniform(df_valid, cond_cols, n_candidates, seed=42):
    """min-max ã®ä¸€æ§˜ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§å€™è£œé›†åˆã‚’ä½œã‚‹"""
    rng = np.random.default_rng(seed)
    mins = df_valid[cond_cols].min().values.astype(float)
    maxs = df_valid[cond_cols].max().values.astype(float)
    # åŒä¸€å€¤ç¯„å›²ã¯åƒ…ã‹ã«åºƒã’ã‚‹ï¼ˆæ•°å€¤å®‰å®šï¼‰
    width = np.maximum(maxs - mins, 1e-12)
    low = mins
    high = mins + width
    Xc = rng.uniform(low=low, high=high, size=(n_candidates, len(cond_cols)))
    cand_df = pd.DataFrame(Xc, columns=cond_cols)
    return cand_df

def safe_hist(values, title, xlabel):
    fig, ax = plt.subplots()
    ax.hist(values, bins=20)
    ax.set_title(title)
    ax.set_xlabel(xlabel)
    ax.set_ylabel("Count")
    st.pyplot(fig)

# ------------------------------------------------------------
# ã‚¿ãƒ–
# ------------------------------------------------------------
tab1, tab2 = st.tabs(["ğŸ“ å®Ÿé¨“ãƒãƒ¼ãƒˆ", "ğŸ“Š è§£æ"])

# ------------------------------------------------------------
# ğŸ“ å®Ÿé¨“ãƒãƒ¼ãƒˆ
# ------------------------------------------------------------
with tab1:
    st.subheader("æ–°ã—ã„å®Ÿé¨“ãƒãƒ¼ãƒˆã‚’è¿½åŠ ")

    with st.form("note_form"):
        purpose = st.text_area("ğŸ¯ ç›®çš„")
        result_text = st.text_area("ğŸ“Š çµæœ")
        discussion = st.text_area("ğŸ’¡ è€ƒå¯Ÿ")
        submitted = st.form_submit_button("ä¿å­˜")

        if submitted:
            notes_df = pd.read_csv(NOTE_FILE)
            exp_id = f"{date.today().strftime('%Y%m%d')}-{len(notes_df)+1:02d}"
            new_note = pd.DataFrame([{
                "å®Ÿé¨“ID": exp_id,
                "æ—¥ä»˜": str(date.today()),
                "ç›®çš„": purpose,
                "çµæœ": result_text,
                "è€ƒå¯Ÿ": discussion
            }])
            notes_df = pd.concat([notes_df, new_note], ignore_index=True)
            notes_df.to_csv(NOTE_FILE, index=False, encoding="utf-8")
            st.success(f"âœ… å®Ÿé¨“ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆID: {exp_id}ï¼‰")

    st.subheader("ğŸ“’ å®Ÿé¨“ãƒãƒ¼ãƒˆä¸€è¦§")
    notes = pd.read_csv(NOTE_FILE)
    st.dataframe(notes, use_container_width=True)

    # --- æ¡ä»¶ã¨çµæœã‚’è¨˜å…¥ ---
    st.subheader("æ¡ä»¶ã¨çµæœã‚’è¨˜å…¥ (CSVç”¨)")
    with st.form("csv_form"):
        conditions = []
        for i in range(st.session_state.num_conditions):
            val = st.number_input(f"âš™ï¸ æ¡ä»¶{i+1}", step=1.0, format="%.4f", key=f"cond_{i}")
            conditions.append(val)

        col_a, col_b = st.columns(2)
        with col_a:
            add_condition = st.form_submit_button("ï¼‹ æ¡ä»¶ã‚’è¿½åŠ ")
        with col_b:
            remove_condition = st.form_submit_button("ï¼ æ¡ä»¶ã‚’å‰Šé™¤")

        if add_condition:
            st.session_state.num_conditions += 1
            df = pd.read_csv(CSV_FILE)
            for i in range(st.session_state.num_conditions):
                col = f"æ¡ä»¶{i+1}"
                if col not in df.columns:
                    df[col] = np.nan
            df.to_csv(CSV_FILE, index=False, encoding="utf-8")
            st.experimental_rerun()

        if remove_condition and st.session_state.num_conditions > 1:
            st.session_state.num_conditions -= 1
            # æ—¢å­˜CSVã®åˆ—ã¯ãã®ã¾ã¾ä¿æŒï¼ˆéå»ãƒ‡ãƒ¼ã‚¿äº’æ›ã®ãŸã‚ï¼‰

        result_val = st.number_input("ğŸ“Š çµæœ", step=1.0, format="%.6f")

        submitted_csv = st.form_submit_button("CSVã«ä¿å­˜")

        if submitted_csv:
            data_df = pd.read_csv(CSV_FILE)
            exp_id = f"{date.today().strftime('%Y%m%d')}-{len(data_df)+1:02d}"
            row = {"å®Ÿé¨“ID": exp_id}
            for i, val in enumerate(conditions):
                row[f"æ¡ä»¶{i+1}"] = val
            row["çµæœ"] = result_val

            # è¶³ã‚Šãªã„åˆ—ã‚’åŸ‹ã‚ã‚‹
            for col in row.keys():
                if col not in data_df.columns:
                    data_df[col] = np.nan

            new_data = pd.DataFrame([row])
            data_df = pd.concat([data_df, new_data], ignore_index=True)
            data_df.to_csv(CSV_FILE, index=False, encoding="utf-8")
            st.success(f"âœ… æ¡ä»¶ã¨çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆID: {exp_id}ï¼‰")

    st.subheader("ğŸ“‘ å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ (CSV)")
    data = pd.read_csv(CSV_FILE)
    st.dataframe(data, use_container_width=True)

# ------------------------------------------------------------
# ğŸ“Š è§£æï¼ˆKanekoå›å¸° + ADï¼‰
# ------------------------------------------------------------
with tab2:
    st.subheader("âœ¨ Kanekoå›å¸° + AD è§£æã§æ¬¡ã®å®Ÿé¨“æ¡ä»¶ã‚’ææ¡ˆ")

    df = pd.read_csv(CSV_FILE)
    all_condition_cols = [c for c in df.columns if c.startswith("æ¡ä»¶")]
    if "çµæœ" not in df.columns:
        st.warning("âš ï¸ CSVã«ã€çµæœã€åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    mode = st.radio("æœ€é©åŒ–ã®ç›®çš„", ["æœ€å¤§åŒ–", "æœ€å°åŒ–"], horizontal=True)

    if not all_condition_cols:
        st.warning("âš ï¸ æ¡ä»¶ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        st.stop()

    selected_conditions = st.multiselect(
        "è§£æã«ä½¿ç”¨ã™ã‚‹æ¡ä»¶åˆ—",
        all_condition_cols,
        default=[all_condition_cols[0]]
    )

    col_top1, col_top2, col_top3 = st.columns(3)
    with col_top1:
        regression_method = st.selectbox(
            "å›å¸°æ‰‹æ³•",
            ["ols_linear", "ols_nonlinear", "svr_linear", "svr_gaussian", "gpr_one_kernel", "gpr_kernels"]
        )
    with col_top2:
        ad_method = st.selectbox("ADæ‰‹æ³•", ["knn", "ocsvm", "ocsvm_gamma_optimization"])
    with col_top3:
        fold_number = st.number_input("CVåˆ†å‰²æ•° (KFold)", min_value=3, max_value=20, value=10, step=1)

    # è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    with st.expander("é«˜åº¦ãªè¨­å®šï¼ˆå¿…è¦ãªã¨ãã ã‘ï¼‰", expanded=False):
        st.caption("SVR/GPRã®è¨­å®šã‚„å€™è£œç‚¹ç”Ÿæˆã®ä»¶æ•°ãªã©ã‚’èª¿æ•´ã§ãã¾ã™ã€‚")
        linear_svr_cs = 2 ** np.arange(-10, 5, dtype=float)
        linear_svr_eps = 2 ** np.arange(-10, 0, dtype=float)
        nonlinear_svr_cs = 2 ** np.arange(-5, 10, dtype=float)
        nonlinear_svr_eps = 2 ** np.arange(-10, 0, dtype=float)
        nonlinear_svr_gammas = 2 ** np.arange(-20, 10, dtype=float)
        ocsvm_nu = st.number_input("OCSVM Î½", min_value=0.001, max_value=0.5, value=0.04, step=0.01)
        ocsvm_gamma_default = st.number_input("OCSVM Î³ (å›ºå®šãƒ¢ãƒ¼ãƒ‰)", min_value=1e-6, max_value=10.0, value=0.1, step=0.1, format="%.6f")
        rate_inside_ad = st.slider("ADã—ãã„å€¤ï¼ˆkNNã§å†…å´ã«å«ã‚ã‚‹å‰²åˆ / OCSVMã¯ç„¡è¦–ï¼‰", 0.5, 0.999, 0.96, 0.005)
        n_candidates = st.number_input("å€™è£œç‚¹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆæœªè©•ä¾¡ï¼‰", min_value=50, max_value=5000, value=500, step=50)
        gpr_kernel_index = st.number_input("GPRå˜ä¸€ã‚«ãƒ¼ãƒãƒ«ç•ªå· (0-10)", min_value=0, max_value=10, value=2, step=1)

    # ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°ãƒã‚§ãƒƒã‚¯
    df_valid = df.dropna(subset=selected_conditions + ["çµæœ"]).copy()
    if df_valid.empty or len(df_valid) < 3 or len(selected_conditions) == 0:
        st.warning("ğŸ“‰ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ç‚¹ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆå°‘ãªãã¨ã‚‚3ç‚¹ã€æ¡ä»¶åˆ—1ã¤ä»¥ä¸Šï¼‰ã€‚")
        st.stop()

    # å…¥å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿
    X = df_valid[selected_conditions].values
    y = df_valid["çµæœ"].values

    # éç·šå½¢å¤‰æ›ï¼ˆOLSã®ã¿ï¼‰
    x_tmp, x_pred_tmp = None, None
    if regression_method == "ols_nonlinear":
        x_tmp = pd.DataFrame(X, columns=selected_conditions)
        x_square = x_tmp ** 2
        X_aug = []
        col_names = []

        # äºŒä¹— & äº¤å·®é …
        for i in range(x_tmp.shape[1]):
            for j in range(x_tmp.shape[1]):
                if i == j:
                    X_aug.append(x_square.iloc[:, i].values)
                    col_names.append(f"{x_square.columns[i]}^2")
                elif i < j:
                    X_aug.append((x_tmp.iloc[:, i] * x_tmp.iloc[:, j]).values)
                    col_names.append(f"{x_tmp.columns[i]}*{x_tmp.columns[j]}")
        if X_aug:
            X = np.column_stack([X] + X_aug)
            selected_conditions = selected_conditions + col_names  # æ‹¡å¼µåã‚’åˆ—åã¨ã—ã¦ç¶™ãè¶³ã™

    # ç‰¹å¾´ã®æ¨™æº–åå·®ã‚¼ãƒ­ã‚’é™¤å»
    X_df = pd.DataFrame(X, columns=selected_conditions)
    deleting_cols = X_df.columns[X_df.std(axis=0, ddof=0) == 0.0].tolist()
    if len(deleting_cols) > 0:
        X_df = X_df.drop(columns=deleting_cols)
        selected_conditions = [c for c in selected_conditions if c not in deleting_cols]
    X = X_df.values

    # ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    X_auto, y_auto, scalers = autoscale_fit_transform(X, y)

    # --------------------------------------------------------
    # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
    # --------------------------------------------------------
    model = None
    kernels = build_kernels(X_auto.shape[1])
    if regression_method == "ols_linear" or regression_method == "ols_nonlinear":
        model = LinearRegression()

    elif regression_method == "svr_linear":
        # C, epsilon ã‚’CVæœ€é©åŒ–
        cv = KFold(n_splits=int(fold_number), shuffle=True, random_state=9)
        grid = {"C": linear_svr_cs, "epsilon": linear_svr_eps}
        gs = GridSearchCV(SVR(kernel="linear"), grid, cv=cv)
        gs.fit(X_auto, y_auto)
        model = SVR(kernel="linear", C=gs.best_params_["C"], epsilon=gs.best_params_["epsilon"])

    elif regression_method == "svr_gaussian":
        # Î³ ã¯ Gram åˆ†æ•£æœ€å¤§åŒ– â†’ ãã®å¾Œ epsilon, C ã‚’CVé¸æŠ
        optimal_gamma = gamma_by_gram_variance(X_auto, 2 ** np.arange(-20, 10, dtype=float))
        cv = KFold(n_splits=int(fold_number), shuffle=True, random_state=9)
        # epsilon æœ€é©åŒ–
        r2_list = []
        for eps in 2 ** np.arange(-10, 0, dtype=float):
            m = SVR(kernel="rbf", C=3, epsilon=eps, gamma=optimal_gamma)
            ycv = cross_val_predict(m, X_auto, y_auto, cv=cv)
            r2_list.append(r2_score(y, inverse_scale_y(ycv, scalers)))
        optimal_eps = 2 ** np.arange(-10, 0, dtype=float)[int(np.argmax(r2_list))]
        # C æœ€é©åŒ–
        r2_list = []
        for Cc in 2 ** np.arange(-5, 10, dtype=float):
            m = SVR(kernel="rbf", C=Cc, epsilon=optimal_eps, gamma=optimal_gamma)
            ycv = cross_val_predict(m, X_auto, y_auto, cv=cv)
            r2_list.append(r2_score(y, inverse_scale_y(ycv, scalers)))
        optimal_C = 2 ** np.arange(-5, 10, dtype=float)[int(np.argmax(r2_list))]
        # Î³ å†æ¢ç´¢
        r2_list = []
        for gg in 2 ** np.arange(-20, 10, dtype=float):
            m = SVR(kernel="rbf", C=optimal_C, epsilon=optimal_eps, gamma=gg)
            ycv = cross_val_predict(m, X_auto, y_auto, cv=cv)
            r2_list.append(r2_score(y, inverse_scale_y(ycv, scalers)))
        optimal_gamma = 2 ** np.arange(-20, 10, dtype=float)[int(np.argmax(r2_list))]
        model = SVR(kernel="rbf", C=optimal_C, epsilon=optimal_eps, gamma=optimal_gamma)

    elif regression_method == "gpr_one_kernel":
        selected_kernel = kernels[int(gpr_kernel_index)]
        model = GaussianProcessRegressor(alpha=0, kernel=selected_kernel)

    elif regression_method == "gpr_kernels":
        cv = KFold(n_splits=int(fold_number), shuffle=True, random_state=9)
        r2cvs = []
        best_k_idx = 0
        for idx, k in enumerate(kernels):
            m = GaussianProcessRegressor(alpha=0, kernel=k)
            ycv = cross_val_predict(m, X_auto, y_auto, cv=cv)
            r2cvs.append(r2_score(y, inverse_scale_y(ycv, scalers)))
            if r2cvs[-1] >= np.max(r2cvs):
                best_k_idx = idx
        st.info(f"CVã§é¸ã°ã‚ŒãŸã‚«ãƒ¼ãƒãƒ«ç•ªå·: {best_k_idx}")
        model = GaussianProcessRegressor(alpha=0, kernel=kernels[best_k_idx])

    # å­¦ç¿’
    model.fit(X_auto, y_auto)

    # --------------------------------------------------------
    # å­¦ç¿’æ€§èƒ½ & CV æ€§èƒ½
    # --------------------------------------------------------
    y_pred_train = inverse_scale_y(model.predict(X_auto), scalers)
    col_m1, col_m2, col_m3 = st.columns(3)
    with col_m1:
        st.metric("RÂ² (train)", f"{r2_score(y, y_pred_train):.4f}")
    with col_m2:
        st.metric("RMSE (train)", f"{mean_squared_error(y, y_pred_train, squared=False):.6g}")
    with col_m3:
        st.metric("MAE (train)", f"{mean_absolute_error(y, y_pred_train):.6g}")

    cv = KFold(n_splits=int(fold_number), shuffle=True, random_state=9)
    y_cv_scaled = cross_val_predict(model, X_auto, y_auto, cv=cv)
    y_cv = inverse_scale_y(y_cv_scaled, scalers)

    col_c1, col_c2, col_c3 = st.columns(3)
    with col_c1:
        st.metric("RÂ² (CV)", f"{r2_score(y, y_cv):.4f}")
    with col_c2:
        st.metric("RMSE (CV)", f"{mean_squared_error(y, y_cv, squared=False):.6g}")
    with col_c3:
        st.metric("MAE (CV)", f"{mean_absolute_error(y, y_cv):.6g}")

    # å®Ÿæ¸¬ vs CVæ¨å®š ãƒ—ãƒ­ãƒƒãƒˆ
    fig_cv, ax_cv = plt.subplots()
    ax_cv.scatter(y, y_cv, c="blue")
    y_max = max(np.max(y), np.max(y_cv))
    y_min = min(np.min(y), np.min(y_cv))
    pad = 0.05 * (y_max - y_min if y_max > y_min else 1.0)
    ax_cv.plot([y_min - pad, y_max + pad], [y_min - pad, y_max + pad], "k-")
    ax_cv.set_xlabel("å®Ÿæ¸¬å€¤")
    ax_cv.set_ylabel("CVæ¨å®šå€¤")
    ax_cv.set_aspect("equal", adjustable="box")
    ax_cv.set_title("å®Ÿæ¸¬ vs CVæ¨å®š")
    st.pyplot(fig_cv)

    # --------------------------------------------------------
    # æœªè©•ä¾¡å€™è£œ ç”Ÿæˆ & äºˆæ¸¬ï¼ˆGPRã¯ä¸ç¢ºã‹ã•ã‚‚ï¼‰
    # --------------------------------------------------------
    st.markdown("---")
    st.subheader("ğŸ”® æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ææ¡ˆï¼ˆå€™è£œç”Ÿæˆ â†’ äºˆæ¸¬ â†’ ADã§ãƒ•ã‚£ãƒ«ã‚¿ï¼‰")

    # å€™è£œç”Ÿæˆï¼ˆmin-maxä¸€æ§˜ï¼‰
    base_cond_cols = [c for c in df.columns if c.startswith("æ¡ä»¶")]  # å…ƒã®ç‰©ç†æ¡ä»¶ã ã‘
    if len(base_cond_cols) == 0:
        st.warning("å€™è£œç”Ÿæˆã®ãŸã‚ã®æ¡ä»¶åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

    cand_df = make_candidates_uniform(df.dropna(subset=base_cond_cols + ["çµæœ"]), base_cond_cols, int(n_candidates))
    # è§£æã«ä½¿ã£ãŸç‰¹å¾´ã¨æ•´åˆã‚’å–ã‚‹ï¼ˆOLS_nonlinear ã§ã¯æ‹¡å¼µç‰¹å¾´ãŒå¿…è¦ï¼‰
    Xc = cand_df[[c for c in base_cond_cols if c in cand_df.columns]].copy()

    if regression_method == "ols_nonlinear":
        # å…ƒã®é¸æŠæ¡ä»¶ï¼ˆæ‹¡å¼µå‰ï¼‰ã‚’æ¨å®š
        # äº¤å·®é …ã‚’å†æ§‹æˆ
        base_cols_used = [c for c in df_valid.columns if c.startswith("æ¡ä»¶")]
        x_pred_tmp = Xc[base_cols_used].copy()
        x_square_pred = x_pred_tmp ** 2
        X_aug = []
        col_names = []

        for i in range(x_pred_tmp.shape[1]):
            for j in range(x_pred_tmp.shape[1]):
                if i == j:
                    X_aug.append(x_square_pred.iloc[:, i].values)
                    col_names.append(f"{x_square_pred.columns[i]}^2")
                elif i < j:
                    X_aug.append((x_pred_tmp.iloc[:, i] * x_pred_tmp.iloc[:, j]).values)
                    col_names.append(f"{x_pred_tmp.columns[i]}*{x_pred_tmp.columns[j]}")
        if X_aug:
            Xc_full = np.column_stack([x_pred_tmp.values] + X_aug)
            Xc_df = pd.DataFrame(Xc_full, columns=base_cols_used + col_names)
        else:
            Xc_df = x_pred_tmp.copy()
        # å­¦ç¿’æ™‚ã«è½ã¨ã—ãŸ0åˆ†æ•£åˆ—ã‚’åˆã‚ã›ã‚‹
        for col in [c for c in selected_conditions if c not in Xc_df.columns]:
            # æ¬ ã‘ã¦ã„ã‚‹æ‹¡å¼µåˆ—ãŒã‚ã‚‹å ´åˆã¯ã€0ã§åŸ‹ã‚ã‚‹ï¼ˆå®Ÿç”¨ä¸Šã®è¿‘ä¼¼ï¼‰
            Xc_df[col] = 0.0
        Xc_df = Xc_df[selected_conditions]
    else:
        # å­¦ç¿’ã§æ®‹ã£ãŸåˆ—é †ã«åˆã‚ã›ã‚‹
        missing_cols = [c for c in selected_conditions if c not in Xc.columns]
        for c in missing_cols:
            # æ‹¡å¼µåˆ—ã¯0ã§åŸ‹ã‚ã‚‹ï¼ˆOLS_nonlinear ä»¥å¤–ã§ã¯åŸºæœ¬ç™ºç”Ÿã—ãªã„ï¼‰
            Xc[c] = 0.0
        Xc_df = Xc[selected_conditions]

    Xc_auto = autoscale_transform(Xc_df.values, scalers)

    if isinstance(model, GaussianProcessRegressor):
        y_pred_c_scaled, y_std_c_scaled = model.predict(Xc_auto, return_std=True)
        y_pred_c = inverse_scale_y(y_pred_c_scaled, scalers)
        y_std_c = y_std_c_scaled * scalers[3]  # y_std
    else:
        y_pred_c_scaled = model.predict(Xc_auto)
        y_pred_c = inverse_scale_y(y_pred_c_scaled, scalers)
        y_std_c = None

    # --------------------------------------------------------
    # AD åˆ¤å®šï¼ˆå€™è£œã«ã‚‚é©ç”¨ï¼‰
    # --------------------------------------------------------
    st.markdown("#### é©ç”¨é ˜åŸŸ (AD) åˆ¤å®š")
    inside_flag_pred = None
    ad_index_pred = None

    if ad_method == "knn":
        k = 5
        ad_model = NearestNeighbors(n_neighbors=k, metric="euclidean")
        ad_model.fit(X_auto)
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®é–¾å€¤æ±ºå®š
        dist_train, _ = ad_model.kneighbors(X_auto, n_neighbors=k+1)  # è‡ªèº«ã‚’å«ã‚€ã®ã§ +1
        mean_dist_train = dist_train[:, 1:].mean(axis=1)
        thr = np.sort(mean_dist_train)[int(round(len(mean_dist_train)*rate_inside_ad)) - 1]
        # å€™è£œã®AD
        dist_pred, _ = ad_model.kneighbors(Xc_auto, n_neighbors=k)
        mean_dist_pred = dist_pred.mean(axis=1)
        inside_flag_pred = (mean_dist_pred <= thr)
        ad_index_pred = mean_dist_pred  # å°ã•ã„ã»ã©å†…å´

        st.caption("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã® kNN å¹³å‡è·é›¢åˆ†å¸ƒ")
        safe_hist(mean_dist_train, "kNN å¹³å‡è·é›¢ï¼ˆå­¦ç¿’ï¼‰", "è·é›¢")
        st.caption("å€™è£œãƒ‡ãƒ¼ã‚¿ã® kNN å¹³å‡è·é›¢åˆ†å¸ƒ")
        safe_hist(mean_dist_pred, "kNN å¹³å‡è·é›¢ï¼ˆå€™è£œï¼‰", "è·é›¢")

    else:
        # OCSVM ç³»
        if ad_method == "ocsvm_gamma_optimization":
            gamma_grid = 2 ** np.arange(-20, 11, dtype=float)
            optimal_gamma = gamma_by_gram_variance(X_auto, gamma_grid)
            st.write(f"OCSVM æœ€é©åŒ–ã•ã‚ŒãŸ Î³ : {optimal_gamma:g}")
            gamma = optimal_gamma
        else:
            gamma = ocsvm_gamma_default

        ad_model = OneClassSVM(kernel="rbf", gamma=gamma, nu=ocsvm_nu)
        ad_model.fit(X_auto)

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¯†åº¦ï¼ˆå‚è€ƒï¼‰
        dd_train = ad_model.decision_function(X_auto)
        st.caption("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã® OCSVM decision_function åˆ†å¸ƒ")
        safe_hist(dd_train, "OCSVM f(x)ï¼ˆå­¦ç¿’ï¼‰", "f(x)")

        # å€™è£œ
        dd_pred = ad_model.decision_function(Xc_auto)
        inside_flag_pred = (dd_pred >= 0)
        ad_index_pred = dd_pred  # å¤§ãã„ã»ã©å†…å´

        st.caption("å€™è£œãƒ‡ãƒ¼ã‚¿ã® OCSVM decision_function åˆ†å¸ƒ")
        safe_hist(dd_pred, "OCSVM f(x)ï¼ˆå€™è£œï¼‰", "f(x)")

    # --------------------------------------------------------
    # ç›®çš„ã«å¿œã˜ãŸã‚¹ã‚³ã‚¢ã¨ä¸Šä½ææ¡ˆ
    # --------------------------------------------------------
    st.markdown("#### ææ¡ˆçµæœ")
    if mode == "æœ€å¤§åŒ–":
        score = y_pred_c.copy()
    else:  # æœ€å°åŒ–
        score = -y_pred_c.copy()

    # ADå¤–ã¯æ¥µç«¯ã«æ‚ªã„ã‚¹ã‚³ã‚¢ã«
    score_filtered = score.copy()
    score_filtered[~inside_flag_pred] = -1e20

    # ä¸Šä½æ¡ˆã®æŠ½å‡º
    top_k = st.number_input("è¡¨ç¤ºã™ã‚‹ä¸Šä½ææ¡ˆæ•°", 1, 50, 5, 1)
    idx_sorted = np.argsort(-score_filtered)  # å¤§ãã„é †
    idx_sorted = [i for i in idx_sorted if inside_flag_pred[i]][:top_k]

    if len(idx_sorted) == 0:
        st.error("ADå†…ã®å€™è£œãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’å¢—ã‚„ã™ã‹ã€ADè¨­å®šã‚’ç·©ã‚ã¦ãã ã•ã„ã€‚")
    else:
        # ãƒ†ãƒ¼ãƒ–ãƒ«æ•´å‚™
        out_rows = []
        for i in idx_sorted:
            row = {col: cand_df.iloc[i][col] if col in cand_df.columns else np.nan for col in cand_df.columns}
            row["äºˆæ¸¬å€¤"] = y_pred_c[i]
            if y_std_c is not None:
                row["äºˆæ¸¬std"] = y_std_c[i]
            row["AD_index"] = ad_index_pred[i]
            out_rows.append(row)
        out_df = pd.DataFrame(out_rows)
        st.dataframe(out_df, use_container_width=True)

        # å…ˆé ­ã‚’ã€Œæ¨å¥¨ #1ã€ã¨ã—ã¦è¡¨ç¤º
        best_idx = idx_sorted[0]
        best_row = cand_df.iloc[best_idx]
        st.success("ğŸš€ æ¨å¥¨ #1ï¼ˆADå†…ï¼‰: " + ", ".join([f"{c}={best_row[c]:.4f}" for c in cand_df.columns]))
        st.write(f"äºˆæ¸¬å€¤: {y_pred_c[best_idx]:.6g}" + (f", äºˆæ¸¬std: {y_std_c[best_idx]:.6g}" if y_std_c is not None else ""))

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨
        st.download_button(
            "â¬‡ï¸ ä¸Šä½ææ¡ˆï¼ˆCSVï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=out_df.to_csv(index=False).encode("utf-8"),
            file_name="proposals_top.csv",
            mime="text/csv",
        )

    # --------------------------------------------------------
    # å¯è¦–åŒ–ï¼ˆ1æ¬¡å…ƒ/å±¥æ­´ï¼‰
    # --------------------------------------------------------
    st.markdown("---")
    viz_mode = st.radio("å¯è¦–åŒ–", ["æ•£å¸ƒå›³ï¼ˆ1è»¸ï¼‰", "æœ€é©åŒ–å±¥æ­´ï¼ˆCVæ¨å®šå€¤ï¼‰"], horizontal=True)

    if viz_mode == "æ•£å¸ƒå›³ï¼ˆ1è»¸ï¼‰":
        if len([c for c in df_valid.columns if c.startswith("æ¡ä»¶")]) == 0:
            st.info("æ•£å¸ƒå›³ã®ãŸã‚ã®æ¡ä»¶åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            xcol = st.selectbox("æ¨ªè»¸ã«ã™ã‚‹æ¡ä»¶åˆ—", [c for c in df_valid.columns if c.startswith("æ¡ä»¶")], index=0)
            fig, ax = plt.subplots()
            ax.scatter(df_valid[xcol], df_valid["çµæœ"], c="blue", label="å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿")
            ax.set_xlabel(xcol)
            ax.set_ylabel("çµæœ")
            ax.set_title(f"{xcol} vs çµæœ")
            st.pyplot(fig)

    else:  # å±¥æ­´ï¼ˆCVæ¨å®šå€¤ã®æ¨ç§»ã‚’å˜ã«ä¸¦ã¹ã‚‹ï¼‰
        fig, ax = plt.subplots()
        ax.plot(range(1, len(y_cv) + 1), y_cv, marker="o")
        ax.set_xlabel("ãƒ‡ãƒ¼ã‚¿ç•ªå·")
        ax.set_ylabel("CVæ¨å®šå€¤")
        ax.set_title("CVæ¨å®šå€¤ã®å±¥æ­´")
        st.pyplot(fig)
